# ui/settings_tab.py
# è¨­å®šã‚¿ãƒ–ã®å®Ÿè£…
# è¡Œæ•°: 250è¡Œ

import streamlit as st
from config import (
    GEMINI_KEY, OPENAI_KEY, ANTHROPIC_KEY, GROQ_KEY, XAI_KEY,
    AI_MODELS, DEFAULT_TEAM_CONFIG, get_team_config, set_team_config, reset_team_config
)
from agents.coder_team import CoderTeam
from agents.auditor_team import AuditorTeam
from agents.data_team import DataTeam
from agents.searcher_team import SearcherTeam

def render_settings_tab():
    """è¨­å®šã‚¿ãƒ–ã‚’ãƒ¬ãƒ³ãƒ€ãƒªãƒ³ã‚°"""
    st.markdown('<div style="font-size: 1.5rem; font-weight: bold; margin-bottom: 1rem;">âš™ï¸ è¨­å®š</div>', unsafe_allow_html=True)
    
    col1, col2 = st.columns(2)
    
    with col1:
        _render_ai_settings()
        st.divider()
        _render_account_settings()
        st.divider()
        _render_team_composition()
    
    with col2:
        _render_service_connections()
        st.divider()
        _render_sharing_settings()
        st.divider()
        _render_system_info()
        st.divider()
        _render_team_evaluation()

def _render_ai_settings():
    """AIã‚«ã‚¹ã‚¿ãƒ è¨­å®š"""
    st.subheader("ğŸ¤– AIã‚«ã‚¹ã‚¿ãƒ è¨­å®š")
    
    st.markdown("ğŸ”„ **ã‚³ãƒ¼ãƒ‰ãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒ«ãƒ¼ãƒ—**")
    use_loop = st.toggle("ãƒ«ãƒ¼ãƒ—æœ‰åŠ¹", value=st.session_state.use_loop, key="settings_use_loop", label_visibility="collapsed")
    st.session_state.use_loop = use_loop
    
    if use_loop:
        max_loop = st.slider("æœ€å¤§ãƒ«ãƒ¼ãƒ—å›æ•°", 1, 5, st.session_state.max_loop, key="settings_max_loop")
        st.session_state.max_loop = max_loop
    
    st.markdown("ğŸ“Š **ã‚¯ãƒ­ã‚¹ãƒã‚§ãƒƒã‚¯æ©Ÿèƒ½**")
    use_crosscheck = st.toggle("ã‚¯ãƒ­ã‚¹ãƒã‚§ãƒƒã‚¯æœ‰åŠ¹", value=st.session_state.use_crosscheck, key="settings_use_crosscheck", label_visibility="collapsed")
    st.session_state.use_crosscheck = use_crosscheck
    
    response_style = st.selectbox("ğŸ’¬ ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå¿œç­”ã‚¹ã‚¿ã‚¤ãƒ«", ["ç°¡æ½”", "è©³ç´°"], index=0 if st.session_state.response_style == "ç°¡æ½”" else 1, key="settings_response_style")
    st.session_state.response_style = response_style
    
    st.markdown("ğŸ’¾ **è‡ªå‹•ä¿å­˜**")
    auto_save = st.toggle("è‡ªå‹•ä¿å­˜æœ‰åŠ¹", value=st.session_state.auto_save, key="settings_auto_save", label_visibility="collapsed")
    st.session_state.auto_save = auto_save

def _render_account_settings():
    """ã‚¢ã‚«ã‚¦ãƒ³ãƒˆè¨­å®š"""
    st.subheader("ğŸ‘¤ ã‚¢ã‚«ã‚¦ãƒ³ãƒˆè¨­å®š")
    
    skills_user_id = st.text_input("Skills User ID", value=st.session_state.skills_user_id, key="settings_skills_user_id", help="Skills Serverã§å–å¾—ã—ãŸãƒ¦ãƒ¼ã‚¶ãƒ¼ID")
    st.session_state.skills_user_id = skills_user_id
    
    display_name = st.text_input("è¡¨ç¤ºå", value=st.session_state.display_name, key="settings_display_name")
    st.session_state.display_name = display_name
    
    user_email = st.text_input("ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹", value=st.session_state.user_email, key="settings_user_email")
    st.session_state.user_email = user_email
    
    if st.button("ğŸ” ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰å¤‰æ›´", use_container_width=True):
        st.info("ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰å¤‰æ›´æ©Ÿèƒ½ã¯æº–å‚™ä¸­ã§ã™")

def _render_team_composition():
    """ãƒãƒ¼ãƒ ç·¨æˆ"""
    st.subheader("ğŸ‘¥ ãƒãƒ¼ãƒ ç·¨æˆ")
    if st.button("ğŸ”„ ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã«æˆ»ã™", key="settings_reset", use_container_width=True):
        reset_team_config()
        st.rerun()
    
    ai_options = list(AI_MODELS.keys())
    ai_names = {k: v["name"] for k, v in AI_MODELS.items()}
    
    for team_key, team_default in DEFAULT_TEAM_CONFIG.items():
        with st.expander(f"**{team_default['name']}**", expanded=False):
            current = get_team_config(team_key)
            leader = st.selectbox("ğŸ‘‘ é•·", ai_options, index=ai_options.index(current["leader"]), key=f"settings_{team_key}_leader", format_func=lambda x: ai_names[x])
            creator = st.selectbox("ğŸ”¨ ä½œæˆå½¹", ai_options, index=ai_options.index(current["creator"]), key=f"settings_{team_key}_creator", format_func=lambda x: ai_names[x])
            checker = st.selectbox("ğŸ” ãƒã‚§ãƒƒã‚¯å½¹", ai_options, index=ai_options.index(current["checker"]), key=f"settings_{team_key}_checker", format_func=lambda x: ai_names[x])
            if leader != current["leader"] or creator != current["creator"] or checker != current["checker"]:
                set_team_config(team_key, leader, creator, checker)

def _render_service_connections():
    """ã‚µãƒ¼ãƒ“ã‚¹é€£æº"""
    st.subheader("ğŸ”— ã‚µãƒ¼ãƒ“ã‚¹é€£æº")
    
    st.markdown("**Google Drive**")
    gdrive_col1, gdrive_col2 = st.columns([3, 1])
    with gdrive_col1:
        st.markdown(f"çŠ¶æ…‹: {'ğŸŸ¢ æ¥ç¶šæ¸ˆã¿' if st.session_state.gdrive_connected else 'ğŸ”´ æœªæ¥ç¶š'}")
    with gdrive_col2:
        if st.button("æ¥ç¶š" if not st.session_state.gdrive_connected else "è§£é™¤", key="gdrive_btn"):
            st.session_state.gdrive_connected = not st.session_state.gdrive_connected
            st.rerun()
    
    st.markdown("**Slack**")
    slack_col1, slack_col2 = st.columns([3, 1])
    with slack_col1:
        st.markdown(f"çŠ¶æ…‹: {'ğŸŸ¢ æ¥ç¶šæ¸ˆã¿' if st.session_state.slack_connected else 'ğŸ”´ æœªæ¥ç¶š'}")
    with slack_col2:
        if st.button("æ¥ç¶š" if not st.session_state.slack_connected else "è§£é™¤", key="slack_btn"):
            st.session_state.slack_connected = not st.session_state.slack_connected
            st.rerun()
    
    st.markdown("**GitHub**")
    github_col1, github_col2 = st.columns([3, 1])
    with github_col1:
        st.markdown(f"çŠ¶æ…‹: {'ğŸŸ¢ æ¥ç¶šæ¸ˆã¿' if st.session_state.github_connected else 'ğŸ”´ æœªæ¥ç¶š'}")
    with github_col2:
        if st.button("æ¥ç¶š" if not st.session_state.github_connected else "è§£é™¤", key="github_btn"):
            st.session_state.github_connected = not st.session_state.github_connected
            st.rerun()
    
    st.markdown("**Skills Server**")
    st.markdown("[ğŸ”— Skills Serverã§ç®¡ç†](https://skills-server-a34a4.web.app/)")

def _render_sharing_settings():
    """å…±æœ‰è¨­å®š"""
    st.subheader("ğŸŒ å…±æœ‰è¨­å®š")
    
    st.markdown("ğŸ“ **ä½œæ¥­ã‚¿ãƒ–ã®å…±æœ‰ã‚’è¨±å¯**")
    share_tabs = st.toggle("ä½œæ¥­ã‚¿ãƒ–å…±æœ‰", value=st.session_state.share_tabs, key="settings_share_tabs", label_visibility="collapsed")
    st.session_state.share_tabs = share_tabs
    
    st.markdown("ğŸ‘¥ **ãƒãƒ¼ãƒ ç·¨æˆã®å…±æœ‰**")
    share_team_config = st.toggle("ãƒãƒ¼ãƒ å…±æœ‰", value=st.session_state.share_team_config, key="settings_share_team", label_visibility="collapsed")
    st.session_state.share_team_config = share_team_config
    
    history_visibility = st.selectbox("å±¥æ­´ã®å…¬é–‹ç¯„å›²", ["è‡ªåˆ†ã®ã¿", "ãƒãƒ¼ãƒ ãƒ¡ãƒ³ãƒãƒ¼", "å…¨å“¡"], index=["è‡ªåˆ†ã®ã¿", "ãƒãƒ¼ãƒ ãƒ¡ãƒ³ãƒãƒ¼", "å…¨å“¡"].index(st.session_state.history_visibility), key="settings_history_visibility")
    st.session_state.history_visibility = history_visibility

def _render_system_info():
    """ã‚·ã‚¹ãƒ†ãƒ æƒ…å ±"""
    st.subheader("ğŸ”‘ ã‚·ã‚¹ãƒ†ãƒ æƒ…å ±")
    
    st.markdown("**APIã‚­ãƒ¼çŠ¶æ…‹**")
    st.markdown(f"- Gemini: {'âœ…' if GEMINI_KEY else 'âŒ'}")
    st.markdown(f"- OpenAI: {'âœ…' if OPENAI_KEY else 'âŒ'}")
    st.markdown(f"- Anthropic: {'âœ…' if ANTHROPIC_KEY else 'âŒ'}")
    st.markdown(f"- Groq: {'âœ…' if GROQ_KEY else 'âŒ'}")
    st.markdown(f"- xAI: {'âœ…' if XAI_KEY else 'âŒ'}")
    
    st.divider()
    
    st.markdown("**ã‚·ã‚¹ãƒ†ãƒ é€æ˜æ€§**")
    try:
        from failure_tracker import FailureTracker
        tracker = FailureTracker()
        stats_24h = tracker.get_failure_rate(24)
        stats_7d = tracker.get_failure_rate(168)
        m1, m2 = st.columns(2)
        with m1:
            st.metric("24æ™‚é–“å¤±æ•—ç‡", f"{stats_24h['failure_rate']}%")
        with m2:
            st.metric("7æ—¥é–“å¤±æ•—ç‡", f"{stats_7d['failure_rate']}%")
        st.caption(f"ç·å®Ÿè¡Œå›æ•°ï¼ˆ24æ™‚é–“ï¼‰: {stats_24h['total_executions']}å›")
    except:
        st.caption("ãƒ‡ãƒ¼ã‚¿æº–å‚™ä¸­...")

def _render_team_evaluation():
    """ãƒãƒ¼ãƒ è©•ä¾¡ã‚·ã‚¹ãƒ†ãƒ """
    st.subheader("ğŸ† ãƒãƒ¼ãƒ è©•ä¾¡")
    
    try:
        from team_evaluator import get_evaluation_manager
        eval_manager = get_evaluation_manager()
        
        # å±¥æ­´ãƒ™ãƒ¼ã‚¹ã®çµ±è¨ˆè¡¨ç¤º
        st.markdown("**ğŸ“Š ãƒãƒ¼ãƒ åˆ¥ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ï¼ˆ30æ—¥é–“ï¼‰**")
        all_teams = eval_manager.get_all_teams_comparison(days=30)
        
        if all_teams:
            for team in all_teams[:5]:
                score = team.get('avg_quality_score')
                score_color = "#10b981" if score and score >= 80 else "#f59e0b" if score and score >= 60 else "#ef4444"
                st.markdown(f'''
                <div style="background:#1e293b;border:1px solid #374151;border-radius:6px;padding:8px;margin:4px 0;">
                    <div style="font-weight:bold;color:#e5e7eb;">{team['team_key']}</div>
                    <div style="font-size:0.85rem;color:#9ca3af;">
                        å“è³ª: <span style="color:{score_color};font-weight:bold;">{score if score else '-'}ç‚¹</span> | 
                        æˆåŠŸç‡: {team.get('success_rate', 0)}% | 
                        å®Ÿè¡Œ: {team.get('total_executions', 0)}å›
                    </div>
                </div>
                ''', unsafe_allow_html=True)
        else:
            st.caption("è©•ä¾¡ãƒ‡ãƒ¼ã‚¿ãªã—ï¼ˆå®Ÿè¡Œã™ã‚‹ã¨è“„ç©ã•ã‚Œã¾ã™ï¼‰")
        
        st.markdown("---")
        
        # ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ãƒ†ã‚¹ãƒˆ
        _render_benchmark_test(eval_manager)
        
        st.markdown("---")
        
        # A/Bãƒ†ã‚¹ãƒˆ  
        _render_ab_test(eval_manager)
        
    except Exception as e:
        st.caption(f"è©•ä¾¡ã‚·ã‚¹ãƒ†ãƒ : {e}")

def _render_benchmark_test(eval_manager):
    """ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ãƒ†ã‚¹ãƒˆ"""
    st.markdown("**ğŸ¯ ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ãƒ†ã‚¹ãƒˆ**")
    benchmark_team = st.selectbox("ãƒ†ã‚¹ãƒˆå¯¾è±¡ãƒãƒ¼ãƒ ", ["coder", "auditor", "data", "searcher"], key="benchmark_team_select")
    
    if st.button("ğŸš€ ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å®Ÿè¡Œ", key="run_benchmark", use_container_width=True):
        with st.spinner(f"ğŸ¯ {benchmark_team}ãƒãƒ¼ãƒ ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å®Ÿè¡Œä¸­..."):
            try:
                team_config = get_team_config(benchmark_team)
                
                def team_runner(task):
                    if benchmark_team == "coder":
                        team = CoderTeam()
                    elif benchmark_team == "auditor":
                        team = AuditorTeam()
                    elif benchmark_team == "data":
                        team = DataTeam()
                    else:
                        team = SearcherTeam()
                    result = team.run(task)
                    return result.get("final_result", "")
                
                result = eval_manager.run_benchmark(benchmark_team, team_config, team_runner)
                
                st.success(f"âœ… ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å®Œäº†: å¹³å‡{result['avg_score']}ç‚¹ / {result['avg_time']}ç§’")
                
                for task_result in result.get('task_results', []):
                    status = "âœ…" if task_result['success'] else "âŒ"
                    st.caption(f"{status} {task_result['name']}: {task_result['score']}ç‚¹")
            except Exception as e:
                st.error(f"âŒ ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å¤±æ•—: {e}")

def _render_ab_test(eval_manager):
    """A/Bãƒ†ã‚¹ãƒˆ"""
    st.markdown("**âš–ï¸ A/Bãƒ†ã‚¹ãƒˆ**")
    ab_task = st.text_input("A/Bãƒ†ã‚¹ãƒˆç”¨ã‚¿ã‚¹ã‚¯", placeholder="Pythonã§ãƒ•ã‚£ãƒœãƒŠãƒƒãƒæ•°åˆ—ã‚’è¨ˆç®—...", key="ab_test_task")
    
    ab_col1, ab_col2 = st.columns(2)
    with ab_col1:
        st.caption("ãƒãƒ¼ãƒ A: ç¾åœ¨ã®è¨­å®š")
    with ab_col2:
        ab_team_b = st.selectbox("ãƒãƒ¼ãƒ B", ["coder", "auditor", "data", "searcher"], key="ab_team_b_select")
    
    if st.button("â–¶ï¸ A/Bãƒ†ã‚¹ãƒˆå®Ÿè¡Œ", key="run_ab_test", use_container_width=True):
        if ab_task.strip():
            with st.spinner("âš–ï¸ A/Bãƒ†ã‚¹ãƒˆå®Ÿè¡Œä¸­..."):
                try:
                    team_a_config = get_team_config("coder")
                    team_b_config = get_team_config(ab_team_b)
                    
                    def team_a_runner(task):
                        team = CoderTeam()
                        result = team.run(task)
                        return result.get("final_result", "")
                    
                    def team_b_runner(task):
                        if ab_team_b == "coder":
                            team = CoderTeam()
                        elif ab_team_b == "auditor":
                            team = AuditorTeam()
                        elif ab_team_b == "data":
                            team = DataTeam()
                        else:
                            team = SearcherTeam()
                        result = team.run(task)
                        return result.get("final_result", "")
                    
                    result = eval_manager.run_ab_test(
                        ab_task, team_a_config, team_b_config,
                        team_a_runner, team_b_runner
                    )
                    
                    winner_text = "ğŸ† ãƒãƒ¼ãƒ Aå‹åˆ©" if result['winner'] == 'team_a' else "ğŸ† ãƒãƒ¼ãƒ Bå‹åˆ©" if result['winner'] == 'team_b' else "ğŸ¤ å¼•ãåˆ†ã‘"
                    st.success(winner_text)
                    
                    r_col1, r_col2 = st.columns(2)
                    with r_col1:
                        st.markdown(f"**ãƒãƒ¼ãƒ A**: {result['team_a']['time']:.2f}ç§’")
                    with r_col2:
                        st.markdown(f"**ãƒãƒ¼ãƒ B**: {result['team_b']['time']:.2f}ç§’")
                except Exception as e:
                    st.error(f"âŒ A/Bãƒ†ã‚¹ãƒˆå¤±æ•—: {e}")
        else:
            st.warning("ã‚¿ã‚¹ã‚¯ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
