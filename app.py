import os
import streamlit as st
from dotenv import load_dotenv

from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_openai import ChatOpenAI
from langchain_anthropic import ChatAnthropic
from langchain_groq import ChatGroq
from langchain_core.messages import HumanMessage, SystemMessage

load_dotenv()

# ==========================================
# ãƒšãƒ¼ã‚¸è¨­å®š
# ==========================================
st.set_page_config(
    page_title="Multi-Agent System",
    page_icon="ğŸ¤–",
    layout="wide"
)

# ==========================================
# APIã‚­ãƒ¼è¨­å®š
# ==========================================
GEMINI_KEY = os.getenv("GEMINI_API_KEY") or os.getenv("GOOGLE_API_KEY")
OPENAI_KEY = os.getenv("OPENAI_API_KEY")
ANTHROPIC_KEY = os.getenv("ANTHROPIC_API_KEY")
GROQ_KEY = os.getenv("GROQ_API_KEY")

if GEMINI_KEY:
    os.environ["GOOGLE_API_KEY"] = GEMINI_KEY

# ==========================================
# ãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–
# ==========================================
@st.cache_resource
def get_commander():
    return ChatGoogleGenerativeAI(model="gemini-3-pro-preview", temperature=0.5)

@st.cache_resource
def get_auditor():
    return ChatOpenAI(model="gpt-5.2", temperature=0, api_key=OPENAI_KEY)

@st.cache_resource
def get_coder():
    return ChatAnthropic(model="claude-sonnet-4-5-20250929", temperature=0, api_key=ANTHROPIC_KEY)

@st.cache_resource
def get_data_processor():
    return ChatGroq(model="llama-3.3-70b-versatile", temperature=0, api_key=GROQ_KEY)

# ==========================================
# ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°
# ==========================================
def extract_content(response):
    """ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡º"""
    content = response.content
    if isinstance(content, list):
        texts = []
        for c in content:
            if isinstance(c, dict) and 'text' in c:
                texts.append(c['text'])
            else:
                texts.append(str(c))
        return " ".join(texts)
    return content

# ==========================================
# ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆé–¢æ•°
# ==========================================
def call_auditor(plan_text: str) -> str:
    """ç›£æŸ»å½¹ã«ä¾é ¼"""
    model = get_auditor()
    messages = [
        SystemMessage(content="ã‚ãªãŸã¯å†·å¾¹ãªç›£æŸ»å½¹ã§ã™ã€‚è¨ˆç”»ã«å¯¾ã—ã€æŠ€è¡“çš„ãƒªã‚¹ã‚¯ã€ã‚³ã‚¹ãƒˆè¶…éãƒªã‚¹ã‚¯ã€å®Ÿç¾å¯èƒ½æ€§ã®æ‡¸å¿µç‚¹ã‚’å³ã—ãæŒ‡æ‘˜ã—ã¦ãã ã•ã„ã€‚æ—¥æœ¬èªã§å›ç­”ã€‚"),
        HumanMessage(content=plan_text)
    ]
    return extract_content(model.invoke(messages))

def call_coder(requirement_text: str) -> str:
    """ã‚³ãƒ¼ãƒ‰å½¹ã«ä¾é ¼"""
    model = get_coder()
    messages = [
        HumanMessage(content=f"ã‚ãªãŸã¯ä¸–ç•Œæœ€é«˜å³°ã®ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ã§ã™ã€‚è¦ä»¶ã«åŸºã¥ãé«˜å“è³ªãªã‚³ãƒ¼ãƒ‰ã‚’æ›¸ã„ã¦ãã ã•ã„ã€‚\n\nè¦ä»¶:\n{requirement_text}")
    ]
    return extract_content(model.invoke(messages))

def call_coder_fix(original_code: str, feedback: str) -> str:
    """ã‚³ãƒ¼ãƒ‰å½¹ã«ä¿®æ­£ä¾é ¼"""
    model = get_coder()
    messages = [
        HumanMessage(content=f"""ã‚ãªãŸã¯ä¸–ç•Œæœ€é«˜å³°ã®ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ã§ã™ã€‚
ä»¥ä¸‹ã®ã‚³ãƒ¼ãƒ‰ã«å¯¾ã™ã‚‹ãƒ¬ãƒ“ãƒ¥ãƒ¼æŒ‡æ‘˜ã‚’å—ã‘ã¦ã€ä¿®æ­£ç‰ˆã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚

ã€å…ƒã®ã‚³ãƒ¼ãƒ‰ã€‘
{original_code}

ã€ãƒ¬ãƒ“ãƒ¥ãƒ¼æŒ‡æ‘˜ã€‘
{feedback}

ä¿®æ­£ç‰ˆã®ã‚³ãƒ¼ãƒ‰ã‚’å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚""")
    ]
    return extract_content(model.invoke(messages))

def call_code_review(code: str) -> dict:
    """ç›£æŸ»å½¹ã«ã‚³ãƒ¼ãƒ‰ãƒ¬ãƒ“ãƒ¥ãƒ¼ä¾é ¼"""
    model = get_auditor()
    messages = [
        SystemMessage(content="""ã‚ãªãŸã¯å³æ ¼ãªã‚³ãƒ¼ãƒ‰ãƒ¬ãƒ“ãƒ¥ã‚¢ãƒ¼ã§ã™ã€‚
ã‚³ãƒ¼ãƒ‰ã‚’åˆ†æã—ã€ä»¥ä¸‹ã®å½¢å¼ã§å›ç­”ã—ã¦ãã ã•ã„ï¼š

ã€åˆ¤å®šã€‘OK ã¾ãŸã¯ è¦ä¿®æ­£
ã€å•é¡Œç‚¹ã€‘ï¼ˆè¦ä¿®æ­£ã®å ´åˆã®ã¿ï¼‰å…·ä½“çš„ãªå•é¡Œç‚¹ã‚’åˆ—æŒ™
ã€æ¨å¥¨ä¿®æ­£ã€‘ï¼ˆè¦ä¿®æ­£ã®å ´åˆã®ã¿ï¼‰ä¿®æ­£æ–¹æ³•ã®ææ¡ˆ

ãƒã‚°ã€ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£å•é¡Œã€ã‚¨ãƒƒã‚¸ã‚±ãƒ¼ã‚¹æœªå¯¾å¿œã€ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹å•é¡Œã‚’é‡ç‚¹çš„ã«ãƒã‚§ãƒƒã‚¯ã—ã¦ãã ã•ã„ã€‚
æ—¥æœ¬èªã§å›ç­”ã€‚"""),
        HumanMessage(content=f"ä»¥ä¸‹ã®ã‚³ãƒ¼ãƒ‰ã‚’ãƒ¬ãƒ“ãƒ¥ãƒ¼ã—ã¦ãã ã•ã„ï¼š\n\n{code}")
    ]
    review = extract_content(model.invoke(messages))
    
    # åˆ¤å®šã‚’æŠ½å‡º
    is_ok = "ã€åˆ¤å®šã€‘OK" in review or "åˆ¤å®šã€‘OK" in review
    return {"approved": is_ok, "feedback": review}

def call_data_processor(text_data: str) -> str:
    """ãƒ‡ãƒ¼ã‚¿å½¹ã«ä¾é ¼"""
    model = get_data_processor()
    messages = [
        SystemMessage(content="ã‚ãªãŸã¯å„ªç§€ãªãƒ‡ãƒ¼ã‚¿å‡¦ç†ä¿‚ã§ã™ã€‚ãƒ†ã‚­ã‚¹ãƒˆã‚’åˆ†æã—ã€é‡è¦ãªãƒã‚¤ãƒ³ãƒˆã‚’è¦ç´„ã—ã¦æ•´ç†ã—ã¦ãã ã•ã„ã€‚æ—¥æœ¬èªã§å›ç­”ã€‚"),
        HumanMessage(content=text_data)
    ]
    return extract_content(model.invoke(messages))

def call_commander(user_input: str, chat_history: list) -> str:
    """å¸ä»¤å¡”ã«ä¾é ¼ï¼ˆã‚¿ã‚¹ã‚¯æŒ¯ã‚Šåˆ†ã‘ï¼‰"""
    model = get_commander()
    
    system_prompt = """ã‚ãªãŸã¯å„ªç§€ãªãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ï¼ˆå¸ä»¤å¡”ï¼‰ã§ã™ã€‚
ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ä¾é ¼ã‚’åˆ†æã—ã€é©åˆ‡ãªéƒ¨ä¸‹ã‚’é¸ã‚“ã§ã‚¿ã‚¹ã‚¯ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚

åˆ©ç”¨å¯èƒ½ãªéƒ¨ä¸‹:
1. ç›£æŸ»å½¹ï¼ˆGPT-5.2ï¼‰- è¨ˆç”»ã®ãƒªã‚¹ã‚¯åˆ†æã€æ‡¸å¿µç‚¹ã®æŒ‡æ‘˜ â†’ [AUDITOR]ã‚¿ã‚°
2. ã‚³ãƒ¼ãƒ‰å½¹ï¼ˆClaude Sonnet 4.5ï¼‰- ã‚³ãƒ¼ãƒ‰å®Ÿè£…ã€ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚° â†’ [CODER]ã‚¿ã‚°
3. ãƒ‡ãƒ¼ã‚¿å½¹ï¼ˆLlama 3.3 70Bï¼‰- ãƒ‡ãƒ¼ã‚¿è¦ç´„ã€æƒ…å ±æ•´ç† â†’ [DATA]ã‚¿ã‚°

å›ç­”å½¢å¼:
- éƒ¨ä¸‹ã‚’ä½¿ã†å ´åˆ: [AUDITOR], [CODER], [DATA]ã®ã„ãšã‚Œã‹ã®ã‚¿ã‚°ã¨ä¾é ¼å†…å®¹ã‚’è¿”ã™
- è‡ªåˆ†ã§å›ç­”ã™ã‚‹å ´åˆ: [SELF]ã‚¿ã‚°ã¨å›ç­”ã‚’è¿”ã™

ã‚³ãƒ¼ãƒ‰ã‚’æ›¸ãä¾é ¼ã®å ´åˆã¯å¿…ãš[CODER]ã‚’ä½¿ã£ã¦ãã ã•ã„ã€‚"""

    messages = [SystemMessage(content=system_prompt)]
    for msg in chat_history[-6:]:
        if msg["role"] == "user":
            messages.append(HumanMessage(content=msg["content"]))
        else:
            messages.append(SystemMessage(content=msg["content"]))
    messages.append(HumanMessage(content=user_input))
    
    return extract_content(model.invoke(messages))

# ==========================================
# ãƒ«ãƒ¼ãƒ—æ§‹é€ ï¼šã‚³ãƒ¼ãƒ‰ç”Ÿæˆâ†’ãƒ¬ãƒ“ãƒ¥ãƒ¼â†’ä¿®æ­£
# ==========================================
def code_with_review_loop(requirement: str, max_iterations: int = 3) -> dict:
    """ã‚³ãƒ¼ãƒ‰ç”Ÿæˆâ†’ãƒ¬ãƒ“ãƒ¥ãƒ¼â†’ä¿®æ­£ã®ãƒ«ãƒ¼ãƒ—"""
    iterations = []
    
    # åˆå›ã‚³ãƒ¼ãƒ‰ç”Ÿæˆ
    st.write("**ğŸ”„ ãƒ«ãƒ¼ãƒ—1: ã‚³ãƒ¼ãƒ‰ç”Ÿæˆä¸­...**")
    code = call_coder(requirement)
    iterations.append({"type": "code", "content": code, "iteration": 1})
    
    for i in range(max_iterations):
        # ãƒ¬ãƒ“ãƒ¥ãƒ¼
        st.write(f"**ğŸ”„ ãƒ«ãƒ¼ãƒ—{i+1}: ã‚³ãƒ¼ãƒ‰ãƒ¬ãƒ“ãƒ¥ãƒ¼ä¸­...**")
        review = call_code_review(code)
        iterations.append({"type": "review", "content": review["feedback"], "iteration": i+1})
        
        if review["approved"]:
            st.success(f"âœ… ãƒ¬ãƒ“ãƒ¥ãƒ¼é€šéï¼ï¼ˆ{i+1}å›ç›®ï¼‰")
            return {
                "final_code": code,
                "iterations": iterations,
                "approved": True,
                "total_iterations": i + 1
            }
        
        # ä¿®æ­£ãŒå¿…è¦
        if i < max_iterations - 1:
            st.warning(f"âš ï¸ è¦ä¿®æ­£ï¼ˆ{i+1}å›ç›®ï¼‰â†’ ä¿®æ­£ä¸­...")
            code = call_coder_fix(code, review["feedback"])
            iterations.append({"type": "fix", "content": code, "iteration": i+2})
    
    # æœ€å¤§å›æ•°åˆ°é”
    st.warning(f"âš ï¸ æœ€å¤§{max_iterations}å›ã®ãƒ«ãƒ¼ãƒ—å®Œäº†ã€‚æœ€çµ‚ç‰ˆã‚’è¿”ã—ã¾ã™ã€‚")
    return {
        "final_code": code,
        "iterations": iterations,
        "approved": False,
        "total_iterations": max_iterations
    }

# ==========================================
# å‡¦ç†ã®æŒ¯ã‚Šåˆ†ã‘

# ==========================================
# ã‚¯ãƒ­ã‚¹ãƒã‚§ãƒƒã‚¯æ©Ÿèƒ½
# ==========================================
def cross_check(agent_type: str, result: str, original_task: str) -> dict:
    """
    ã‚¯ãƒ­ã‚¹ãƒã‚§ãƒƒã‚¯æ©Ÿèƒ½: ä»–ã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒçµæœã‚’100ç‚¹æº€ç‚¹ã§æ¡ç‚¹
    
    Args:
        agent_type: å®Ÿè¡Œã—ãŸã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ ("auditor", "coder", "data")
        result: ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®å‡ºåŠ›çµæœ
        original_task: å…ƒã®ã‚¿ã‚¹ã‚¯å†…å®¹
    
    Returns:
        dict: æ¡ç‚¹çµæœã¨æ”¹å–„ææ¡ˆ
    """
    # å®Ÿè¡Œã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆä»¥å¤–ã®2ã¤ã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã§ãƒã‚§ãƒƒã‚¯
    checkers = []
    if agent_type != "auditor":
        checkers.append(("auditor", get_auditor(), "ğŸ‘®â€â™‚ï¸ ç›£æŸ»å½¹(GPT-5.2)"))
    if agent_type != "coder":
        checkers.append(("coder", get_coder(), "ğŸ‘¨â€ğŸ’» ã‚³ãƒ¼ãƒ‰å½¹(Claude Sonnet 4.5)"))
    if agent_type != "data":
        checkers.append(("data", get_data_processor(), "ğŸ¦™ ãƒ‡ãƒ¼ã‚¿å½¹(Llama 3.3 70B)"))
    
    # æœ€å¤§2ã¤ã®ãƒã‚§ãƒƒã‚«ãƒ¼ã‚’é¸æŠ
    checkers = checkers[:2]
    
    check_results = []
    
    for checker_type, checker_model, checker_name in checkers:
        prompt = f"""ä»¥ä¸‹ã®å‡ºåŠ›çµæœã‚’100ç‚¹æº€ç‚¹ã§æ¡ç‚¹ã—ã¦ãã ã•ã„ã€‚

ã€å…ƒã®ã‚¿ã‚¹ã‚¯ã€‘
{original_task}

ã€å®Ÿè¡Œã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®å‡ºåŠ›ã€‘
{result}

ã€æ¡ç‚¹åŸºæº–ã€‘
1. æ­£ç¢ºæ€§ (25ç‚¹): ã‚¿ã‚¹ã‚¯ã®è¦æ±‚ã‚’æ­£ç¢ºã«æº€ãŸã—ã¦ã„ã‚‹ã‹
2. å¦¥å½“æ€§ (25ç‚¹): ãƒ­ã‚¸ãƒƒã‚¯ã‚„è«–ç†å±•é–‹ãŒå¦¥å½“ã‹
3. ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ (25ç‚¹): ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒªã‚¹ã‚¯ã¯ãªã„ã‹
4. ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ (25ç‚¹): åŠ¹ç‡çš„ã§æœ€é©ãªå®Ÿè£…/å›ç­”ã‹

ã€å‡ºåŠ›å½¢å¼ã€‘
æ­£ç¢ºæ€§: X/25ç‚¹
å¦¥å½“æ€§: Y/25ç‚¹
ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£: Z/25ç‚¹
ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹: W/25ç‚¹
åˆè¨ˆ: N/100ç‚¹

æ”¹å–„ææ¡ˆ:
- å…·ä½“çš„ãªæ”¹å–„ç‚¹ã‚’ç®‡æ¡æ›¸ãã§è¨˜è¼‰
"""
        
        try:
            messages = [HumanMessage(content=prompt)]
            response = checker_model.invoke(messages)
            check_results.append({
                "checker": checker_name,
                "evaluation": response.content
            })
        except Exception as e:
            check_results.append({
                "checker": checker_name,
                "evaluation": f"âŒ è©•ä¾¡ã‚¨ãƒ©ãƒ¼: {str(e)}"
            })
    
    return {
        "checks": check_results,
        "total_checkers": len(check_results)
    }


# ==========================================
def process_command(commander_response: str, original_input: str, use_loop: bool, use_crosscheck: bool = True) -> tuple:
    """å¸ä»¤å¡”ã®æŒ‡ç¤ºã‚’å‡¦ç†ï¼ˆã‚¯ãƒ­ã‚¹ãƒã‚§ãƒƒã‚¯å¯¾å¿œï¼‰"""
    agent_type = None
    result = None
    loop_data = None
    task = original_input
    
    if "[AUDITOR]" in commander_response:
        task = commander_response.split("[AUDITOR]")[-1].strip() or original_input
        agent_type = "auditor"
        result = call_auditor(task)
    
    elif "[CODER]" in commander_response:
        task = commander_response.split("[CODER]")[-1].strip() or original_input
        if use_loop:
            loop_result = code_with_review_loop(task)
            agent_type = "coder_loop"
            result = loop_result["final_code"]
            loop_data = loop_result
        else:
            agent_type = "coder"
            result = call_coder(task)
    
    elif "[DATA]" in commander_response:
        task = commander_response.split("[DATA]")[-1].strip() or original_input
        agent_type = "data"
        result = call_data_processor(task)
    
    else:
        clean_response = commander_response.replace("[SELF]", "").strip()
        return "self", clean_response, None
    
    # ã‚¯ãƒ­ã‚¹ãƒã‚§ãƒƒã‚¯å®Ÿè¡Œï¼ˆselfãƒ¢ãƒ¼ãƒ‰ä»¥å¤–ã€ã‹ã¤use_crosscheck=Trueï¼‰
    crosscheck_data = None
    if use_crosscheck and agent_type and agent_type != "coder_loop":  # ãƒ«ãƒ¼ãƒ—ãƒ¢ãƒ¼ãƒ‰ã¯æ—¢ã«ãƒ¬ãƒ“ãƒ¥ãƒ¼æ¸ˆã¿
        crosscheck_data = cross_check(agent_type, result, task)
    
    return agent_type, result, {"loop_data": loop_data, "crosscheck": crosscheck_data}

# ==========================================
# UI
# ==========================================
st.title("ğŸ¤– Multi-Agent System")
st.markdown("**2026å¹´1æœˆç‰ˆ - ãƒ«ãƒ¼ãƒ—æ§‹é€  + ã‚¯ãƒ­ã‚¹ãƒã‚§ãƒƒã‚¯æ­è¼‰**")

# ã‚µã‚¤ãƒ‰ãƒãƒ¼
with st.sidebar:
    st.header("ğŸ‘¥ ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒãƒ¼ãƒ ")
    st.markdown("""
    | å½¹å‰² | ãƒ¢ãƒ‡ãƒ« |
    |------|--------|
    | ğŸ‘‘ å¸ä»¤å¡” | Gemini 3 Pro |
    | ğŸ‘®â€â™‚ï¸ ç›£æŸ»å½¹ | GPT-5.2 |
    | ğŸ‘¨â€ğŸ’» ã‚³ãƒ¼ãƒ‰å½¹ | Claude Sonnet 4.5 |
    | ğŸ¦™ ãƒ‡ãƒ¼ã‚¿å½¹ | Llama 3.3 70B |
    """)
    
    st.divider()
    
    # ãƒ«ãƒ¼ãƒ—æ§‹é€ ON/OFF
    st.header("âš™ï¸ è¨­å®š")
    use_loop = st.toggle("ğŸ”„ ã‚³ãƒ¼ãƒ‰ãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒ«ãƒ¼ãƒ—", value=True, help="ONã«ã™ã‚‹ã¨ã‚³ãƒ¼ãƒ‰ç”Ÿæˆå¾Œã«è‡ªå‹•ã§GPTãŒãƒ¬ãƒ“ãƒ¥ãƒ¼ã—ã€å•é¡ŒãŒã‚ã‚Œã°ClaudeãŒä¿®æ­£ã—ã¾ã™")
    max_loop = st.slider("æœ€å¤§ãƒ«ãƒ¼ãƒ—å›æ•°", 1, 5, 3) if use_loop else 1
    
    use_crosscheck = st.toggle("ğŸ“Š ã‚¯ãƒ­ã‚¹ãƒã‚§ãƒƒã‚¯æ©Ÿèƒ½", value=True, help="ONã«ã™ã‚‹ã¨ä»–ã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒçµæœã‚’100ç‚¹æº€ç‚¹ã§æ¡ç‚¹ã—ã¾ã™ï¼ˆå‡¦ç†æ™‚é–“å¢—åŠ ï¼‰")
    
    st.divider()
    
    st.header("ğŸ”‘ APIã‚­ãƒ¼çŠ¶æ…‹")
    st.markdown(f"- Gemini: {'âœ…' if GEMINI_KEY else 'âŒ'}")
    st.markdown(f"- OpenAI: {'âœ…' if OPENAI_KEY else 'âŒ'}")
    st.markdown(f"- Anthropic: {'âœ…' if ANTHROPIC_KEY else 'âŒ'}")
    st.markdown(f"- Groq: {'âœ…' if GROQ_KEY else 'âŒ'}")
    
    st.divider()
    
    if st.button("ğŸ—‘ï¸ ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã‚’ã‚¯ãƒªã‚¢"):
        st.session_state.messages = []
        st.rerun()
    
    st.divider()
    
    # ç‚¹æ•°çª“ï¼ˆã‚µã‚¤ãƒ‰ãƒãƒ¼ï¼‰
    st.header("ğŸ“Š ã‚¯ãƒ­ã‚¹ãƒã‚§ãƒƒã‚¯çµæœ")
    
    if "messages" in st.session_state and st.session_state.messages and len(st.session_state.messages) > 0:
        last_msg = st.session_state.messages[-1]
        if last_msg.get("role") == "assistant" and last_msg.get("crosscheck"):
            crosscheck = last_msg["crosscheck"]
            for check in crosscheck["checks"]:
                st.markdown(f"**{check['checker']}**")
                st.text_area("è©•ä¾¡", check["evaluation"], height=200, disabled=True, key=check["checker"])
                st.divider()
        else:
            st.markdown("**ğŸ‘®â€â™‚ï¸ ç›£æŸ»å½¹**")
            st.info("å¾…æ©Ÿä¸­...")
            st.markdown("**ğŸ¦™ ãƒ‡ãƒ¼ã‚¿å½¹**")
            st.info("å¾…æ©Ÿä¸­...")
    else:
        st.markdown("**ğŸ‘®â€â™‚ï¸ ç›£æŸ»å½¹**")
        st.info("å¾…æ©Ÿä¸­...")
        st.markdown("**ğŸ¦™ ãƒ‡ãƒ¼ã‚¿å½¹**")
        st.info("å¾…æ©Ÿä¸­...")

# APIã‚­ãƒ¼ãƒã‚§ãƒƒã‚¯
missing_keys = []
if not GEMINI_KEY: missing_keys.append("GEMINI_API_KEY")
if not OPENAI_KEY: missing_keys.append("OPENAI_API_KEY")
if not ANTHROPIC_KEY: missing_keys.append("ANTHROPIC_API_KEY")
if not GROQ_KEY: missing_keys.append("GROQ_API_KEY")

if missing_keys:
    st.error(f"âŒ ä»¥ä¸‹ã®APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“: {', '.join(missing_keys)}")
    st.stop()

# ãƒãƒ£ãƒƒãƒˆå±¥æ­´åˆæœŸåŒ–
if "messages" not in st.session_state:
    st.session_state.messages = []


# ãƒãƒ£ãƒƒãƒˆå±¥æ­´è¡¨ç¤º
for message in st.session_state.messages:
    with st.chat_message(message["role"], avatar=message.get("avatar")):
        st.markdown(message["content"])

# ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›
if prompt := st.chat_input("ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„..."):
    st.session_state.messages.append({"role": "user", "content": prompt, "avatar": "ğŸ‘¤"})
    with st.chat_message("user", avatar="ğŸ‘¤"):
        st.markdown(prompt)
    
    with st.chat_message("assistant", avatar="ğŸ‘‘"):
        with st.spinner("ğŸ¤” Geminiå¸ä»¤å¡”ãŒæ€è€ƒä¸­..."):
            try:
                commander_response = call_commander(prompt, st.session_state.messages)
                agent_type, result, loop_data = process_command(commander_response, prompt, use_loop, use_crosscheck)
                
                agent_info = {
                    "auditor": "ğŸ‘®â€â™‚ï¸ ç›£æŸ»å½¹(GPT-5.2)",
                    "coder": "ğŸ‘¨â€ğŸ’» ã‚³ãƒ¼ãƒ‰å½¹(Claude Sonnet 4.5)",
                    "coder_loop": "ğŸ‘¨â€ğŸ’» ã‚³ãƒ¼ãƒ‰å½¹ + ğŸ‘®â€â™‚ï¸ ç›£æŸ»å½¹ï¼ˆãƒ«ãƒ¼ãƒ—ï¼‰",
                    "data": "ğŸ¦™ ãƒ‡ãƒ¼ã‚¿å½¹(Llama 3.3 70B)",
                    "self": "ğŸ‘‘ å¸ä»¤å¡”(Gemini 3 Pro)"
                }
                
                if agent_type != "self":
                    st.info(f"ğŸ“‹ {agent_info.get(agent_type, 'ä¸æ˜')} ã«ä¾é ¼ã—ã¾ã—ãŸ")
                
                # ãƒ«ãƒ¼ãƒ—çµæœã®è©³ç´°è¡¨ç¤º
                if loop_data and loop_data.get("loop_data"):
                    with st.expander(f"ğŸ”„ ãƒ«ãƒ¼ãƒ—è©³ç´°ï¼ˆ{loop_data['loop_data']['total_iterations']}å›ï¼‰", expanded=False):
                        for item in loop_data["loop_data"]["iterations"]:
                            if item["type"] == "code":
                                st.markdown(f"**ğŸ“ ã‚³ãƒ¼ãƒ‰ç”Ÿæˆ (v{item['iteration']})**")
                            elif item["type"] == "review":
                                st.markdown(f"**ğŸ” ãƒ¬ãƒ“ãƒ¥ãƒ¼çµæœ**")
                            elif item["type"] == "fix":
                                st.markdown(f"**ğŸ”§ ä¿®æ­£ç‰ˆ (v{item['iteration']})**")
                            st.code(item["content"][:500] + "..." if len(item["content"]) > 500 else item["content"])
                            st.divider()
                

                
                st.markdown(result)
                
                st.session_state.messages.append({
                    "role": "assistant",
                    "content": result,
                    "avatar": "ğŸ‘‘",
                    "agent": agent_type,
                    "crosscheck": loop_data.get("crosscheck") if loop_data else None
                })
                
            except Exception as e:
                st.error(f"âŒ ã‚¨ãƒ©ãƒ¼: {str(e)}")
                import traceback
                st.code(traceback.format_exc())
