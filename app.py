import os
import streamlit as st
from dotenv import load_dotenv

from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_openai import ChatOpenAI
from langchain_anthropic import ChatAnthropic
from langchain_groq import ChatGroq
from langchain_core.messages import HumanMessage, SystemMessage

# ç’°å¢ƒå¤‰æ•°ã‚’èª­ã¿è¾¼ã‚€ï¼ˆæœ€åˆã«å®Ÿè¡Œï¼‰
load_dotenv()

# ==========================================
# ãƒšãƒ¼ã‚¸è¨­å®š
# ==========================================
st.set_page_config(
    page_title="Multi-Agent System",
    page_icon="ğŸ¤–",
    layout="wide"
)

# ==========================================
# APIã‚­ãƒ¼è¨­å®šï¼ˆãƒ­ãƒ¼ã‚«ãƒ«.envå„ªå…ˆï¼‰
# ==========================================
GEMINI_KEY = os.getenv("GEMINI_API_KEY") or os.getenv("GOOGLE_API_KEY")
OPENAI_KEY = os.getenv("OPENAI_API_KEY")
ANTHROPIC_KEY = os.getenv("ANTHROPIC_API_KEY")
GROQ_KEY = os.getenv("GROQ_API_KEY")

# Google APIã‚­ãƒ¼ã‚’ç’°å¢ƒå¤‰æ•°ã«ã‚»ãƒƒãƒˆ
if GEMINI_KEY:
    os.environ["GOOGLE_API_KEY"] = GEMINI_KEY

# ==========================================
# ãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–
# ==========================================
@st.cache_resource
def get_commander():
    """å¸ä»¤å¡” (Gemini 3 Pro)"""
    return ChatGoogleGenerativeAI(
        model="gemini-3-pro-preview",
        temperature=0.5,
    )

@st.cache_resource
def get_auditor():
    """ç›£æŸ»å½¹ (GPT-5.2)"""
    return ChatOpenAI(
        model="gpt-5.2",
        temperature=0,
        api_key=OPENAI_KEY
    )

@st.cache_resource
def get_coder():
    """ã‚³ãƒ¼ãƒ‰å½¹ (Claude Sonnet 4.5)"""
    return ChatAnthropic(
        model="claude-sonnet-4-5-20250929",
        temperature=0,
        api_key=ANTHROPIC_KEY
    )

@st.cache_resource
def get_data_processor():
    """ãƒ‡ãƒ¼ã‚¿å½¹ (Llama 3.3 70B)"""
    return ChatGroq(
        model="llama-3.3-70b-versatile",
        temperature=0,
        api_key=GROQ_KEY
    )

# ==========================================
# ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆé–¢æ•°
# ==========================================
def call_auditor(plan_text: str) -> str:
    """ç›£æŸ»å½¹ã«ä¾é ¼"""
    model = get_auditor()
    messages = [
        SystemMessage(content="ã‚ãªãŸã¯å†·å¾¹ãªç›£æŸ»å½¹ã§ã™ã€‚è¨ˆç”»ã«å¯¾ã—ã€æŠ€è¡“çš„ãƒªã‚¹ã‚¯ã€ã‚³ã‚¹ãƒˆè¶…éãƒªã‚¹ã‚¯ã€å®Ÿç¾å¯èƒ½æ€§ã®æ‡¸å¿µç‚¹ã‚’å³ã—ãæŒ‡æ‘˜ã—ã¦ãã ã•ã„ã€‚æ—¥æœ¬èªã§å›ç­”ã€‚"),
        HumanMessage(content=plan_text)
    ]
    response = model.invoke(messages)
    return response.content

def call_coder(requirement_text: str) -> str:
    """ã‚³ãƒ¼ãƒ‰å½¹ã«ä¾é ¼"""
    model = get_coder()
    messages = [
        HumanMessage(content=f"ã‚ãªãŸã¯ä¸–ç•Œæœ€é«˜å³°ã®ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ã§ã™ã€‚è¦ä»¶ã«åŸºã¥ãé«˜å“è³ªãªã‚³ãƒ¼ãƒ‰ã‚’æ›¸ã„ã¦ãã ã•ã„ã€‚\n\nè¦ä»¶:\n{requirement_text}")
    ]
    response = model.invoke(messages)
    return response.content

def call_data_processor(text_data: str) -> str:
    """ãƒ‡ãƒ¼ã‚¿å½¹ã«ä¾é ¼"""
    model = get_data_processor()
    messages = [
        SystemMessage(content="ã‚ãªãŸã¯å„ªç§€ãªãƒ‡ãƒ¼ã‚¿å‡¦ç†ä¿‚ã§ã™ã€‚ãƒ†ã‚­ã‚¹ãƒˆã‚’åˆ†æã—ã€é‡è¦ãªãƒã‚¤ãƒ³ãƒˆã‚’è¦ç´„ã—ã¦æ•´ç†ã—ã¦ãã ã•ã„ã€‚æ—¥æœ¬èªã§å›ç­”ã€‚"),
        HumanMessage(content=text_data)
    ]
    response = model.invoke(messages)
    return response.content

def call_commander(user_input: str, chat_history: list) -> str:
    """å¸ä»¤å¡”ã«ä¾é ¼ï¼ˆã‚¿ã‚¹ã‚¯æŒ¯ã‚Šåˆ†ã‘ï¼‰"""
    model = get_commander()
    
    system_prompt = """ã‚ãªãŸã¯å„ªç§€ãªãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ï¼ˆå¸ä»¤å¡”ï¼‰ã§ã™ã€‚
ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ä¾é ¼ã‚’åˆ†æã—ã€é©åˆ‡ãªéƒ¨ä¸‹ã‚’é¸ã‚“ã§ã‚¿ã‚¹ã‚¯ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚

åˆ©ç”¨å¯èƒ½ãªéƒ¨ä¸‹:
1. ç›£æŸ»å½¹ï¼ˆGPT-5.2ï¼‰- è¨ˆç”»ã®ãƒªã‚¹ã‚¯åˆ†æã€æ‡¸å¿µç‚¹ã®æŒ‡æ‘˜ â†’ [AUDITOR]ã‚¿ã‚°ã§å‘¼ã³å‡ºã—
2. ã‚³ãƒ¼ãƒ‰å½¹ï¼ˆClaude Sonnet 4.5ï¼‰- ã‚³ãƒ¼ãƒ‰å®Ÿè£…ã€ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚° â†’ [CODER]ã‚¿ã‚°ã§å‘¼ã³å‡ºã—
3. ãƒ‡ãƒ¼ã‚¿å½¹ï¼ˆLlama 3.3 70Bï¼‰- ãƒ‡ãƒ¼ã‚¿è¦ç´„ã€æƒ…å ±æ•´ç† â†’ [DATA]ã‚¿ã‚°ã§å‘¼ã³å‡ºã—

å›ç­”å½¢å¼:
- éƒ¨ä¸‹ã‚’ä½¿ã†å ´åˆ: [AUDITOR], [CODER], [DATA]ã®ã„ãšã‚Œã‹ã®ã‚¿ã‚°ã¨ä¾é ¼å†…å®¹ã‚’è¿”ã™
- è‡ªåˆ†ã§å›ç­”ã™ã‚‹å ´åˆ: [SELF]ã‚¿ã‚°ã¨å›ç­”ã‚’è¿”ã™

ä¾‹:
- ã€Œã‚³ãƒ¼ãƒ‰ã‚’æ›¸ã„ã¦ã€â†’ [CODER] Pythonã§ãƒ•ã‚£ãƒœãƒŠãƒƒãƒæ•°åˆ—ã‚’è¨ˆç®—ã™ã‚‹é–¢æ•°
- ã€Œã“ã®è¨ˆç”»ã®ãƒªã‚¹ã‚¯ã¯ï¼Ÿã€â†’ [AUDITOR] ECã‚µã‚¤ãƒˆæ§‹ç¯‰è¨ˆç”»ã®ãƒªã‚¹ã‚¯åˆ†æ
- ã€Œè¦ç´„ã—ã¦ã€â†’ [DATA] ä»¥ä¸‹ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’è¦ç´„...
- ã€Œã“ã‚“ã«ã¡ã¯ã€â†’ [SELF] ã“ã‚“ã«ã¡ã¯ï¼ä½•ã‹ãŠæ‰‹ä¼ã„ã§ãã‚‹ã“ã¨ã¯ã‚ã‚Šã¾ã™ã‹ï¼Ÿ"""

    messages = [SystemMessage(content=system_prompt)]
    
    # ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã‚’è¿½åŠ 
    for msg in chat_history[-6:]:  # ç›´è¿‘6ä»¶ã®ã¿
        if msg["role"] == "user":
            messages.append(HumanMessage(content=msg["content"]))
        else:
            messages.append(SystemMessage(content=msg["content"]))
    
    messages.append(HumanMessage(content=user_input))
    
    response = model.invoke(messages)
    return response.content

def process_command(commander_response: str, original_input: str) -> tuple:
    """å¸ä»¤å¡”ã®æŒ‡ç¤ºã‚’å‡¦ç†"""
    if "[AUDITOR]" in commander_response:
        task = commander_response.split("[AUDITOR]")[-1].strip()
        if not task:
            task = original_input
        return "auditor", call_auditor(task)
    elif "[CODER]" in commander_response:
        task = commander_response.split("[CODER]")[-1].strip()
        if not task:
            task = original_input
        return "coder", call_coder(task)
    elif "[DATA]" in commander_response:
        task = commander_response.split("[DATA]")[-1].strip()
        if not task:
            task = original_input
        return "data", call_data_processor(task)
    else:
        # [SELF]ã¾ãŸã¯åˆ¤å®šä¸èƒ½ã®å ´åˆã¯å¸ä»¤å¡”ã®å›ç­”ã‚’ãã®ã¾ã¾ä½¿ã†
        clean_response = commander_response.replace("[SELF]", "").strip()
        return "self", clean_response

# ==========================================
# UI
# ==========================================
st.title("ğŸ¤– Multi-Agent System")
st.markdown("**2026å¹´1æœˆç‰ˆ - 4ã¤ã®LLMãŒå”åŠ›ã—ã¦ã‚¿ã‚¹ã‚¯ã‚’å®Ÿè¡Œ**")

# ã‚µã‚¤ãƒ‰ãƒãƒ¼: ãƒãƒ¼ãƒ ç´¹ä»‹
with st.sidebar:
    st.header("ğŸ‘¥ ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒãƒ¼ãƒ ")
    st.markdown("""
    | å½¹å‰² | ãƒ¢ãƒ‡ãƒ« |
    |------|--------|
    | ğŸ‘‘ å¸ä»¤å¡” | Gemini 3 Pro |
    | ğŸ‘®â€â™‚ï¸ ç›£æŸ»å½¹ | GPT-5.2 |
    | ğŸ‘¨â€ğŸ’» ã‚³ãƒ¼ãƒ‰å½¹ | Claude Sonnet 4.5 |
    | ğŸ¦™ ãƒ‡ãƒ¼ã‚¿å½¹ | Llama 3.3 70B |
    """)
    
    st.divider()
    
    # APIã‚­ãƒ¼çŠ¶æ…‹è¡¨ç¤º
    st.header("ğŸ”‘ APIã‚­ãƒ¼çŠ¶æ…‹")
    st.markdown(f"- Gemini: {'âœ…' if GEMINI_KEY else 'âŒ'}")
    st.markdown(f"- OpenAI: {'âœ…' if OPENAI_KEY else 'âŒ'}")
    st.markdown(f"- Anthropic: {'âœ…' if ANTHROPIC_KEY else 'âŒ'}")
    st.markdown(f"- Groq: {'âœ…' if GROQ_KEY else 'âŒ'}")
    
    st.divider()
    
    if st.button("ğŸ—‘ï¸ ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã‚’ã‚¯ãƒªã‚¢"):
        st.session_state.messages = []
        st.rerun()

# APIã‚­ãƒ¼ãƒã‚§ãƒƒã‚¯
missing_keys = []
if not GEMINI_KEY:
    missing_keys.append("GEMINI_API_KEY")
if not OPENAI_KEY:
    missing_keys.append("OPENAI_API_KEY")
if not ANTHROPIC_KEY:
    missing_keys.append("ANTHROPIC_API_KEY")
if not GROQ_KEY:
    missing_keys.append("GROQ_API_KEY")

if missing_keys:
    st.error(f"âŒ ä»¥ä¸‹ã®APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“: {', '.join(missing_keys)}")
    st.info("ğŸ’¡ .envãƒ•ã‚¡ã‚¤ãƒ«ã«APIã‚­ãƒ¼ã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚")
    st.stop()

# ãƒãƒ£ãƒƒãƒˆå±¥æ­´åˆæœŸåŒ–
if "messages" not in st.session_state:
    st.session_state.messages = []

# ãƒãƒ£ãƒƒãƒˆå±¥æ­´è¡¨ç¤º
for message in st.session_state.messages:
    with st.chat_message(message["role"], avatar=message.get("avatar")):
        st.markdown(message["content"])

# ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›
if prompt := st.chat_input("ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„..."):
    # ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¿½åŠ 
    st.session_state.messages.append({"role": "user", "content": prompt, "avatar": "ğŸ‘¤"})
    with st.chat_message("user", avatar="ğŸ‘¤"):
        st.markdown(prompt)
    
    # å¸ä»¤å¡”ãŒåˆ¤æ–­
    with st.chat_message("assistant", avatar="ğŸ‘‘"):
        with st.spinner("ğŸ¤” Geminiå¸ä»¤å¡”ãŒæ€è€ƒä¸­..."):
            try:
                commander_response = call_commander(prompt, st.session_state.messages)
                agent_type, result = process_command(commander_response, prompt)
                
                # ä½¿ç”¨ã—ãŸã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’è¡¨ç¤º
                agent_info = {
                    "auditor": ("ğŸ‘®â€â™‚ï¸ ç›£æŸ»å½¹(GPT-5.2)", "auditor"),
                    "coder": ("ğŸ‘¨â€ğŸ’» ã‚³ãƒ¼ãƒ‰å½¹(Claude Sonnet 4.5)", "coder"),
                    "data": ("ğŸ¦™ ãƒ‡ãƒ¼ã‚¿å½¹(Llama 3.3 70B)", "data"),
                    "self": ("ğŸ‘‘ å¸ä»¤å¡”(Gemini 3 Pro)", "self")
                }
                
                agent_name, _ = agent_info.get(agent_type, ("ğŸ‘‘ å¸ä»¤å¡”", "self"))
                
                if agent_type != "self":
                    st.info(f"ğŸ“‹ {agent_name} ã«ä¾é ¼ã—ã¾ã—ãŸ")
                
                st.markdown(result)
                
                # å±¥æ­´ã«è¿½åŠ 
                st.session_state.messages.append({
                    "role": "assistant",
                    "content": result,
                    "avatar": "ğŸ‘‘",
                    "agent": agent_type
                })
                
            except Exception as e:
                st.error(f"âŒ ã‚¨ãƒ©ãƒ¼: {str(e)}")
                import traceback
                st.code(traceback.format_exc())
